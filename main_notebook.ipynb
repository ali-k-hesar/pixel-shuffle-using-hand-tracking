{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "yolov8_model_type = 'm' # Choose between \"n\" for nano, \"m\" for medium, \"l\" for large, \"x\" for X-large\n",
    "webcam_number = 0 # Specific webcam number based on total webcams connected to your computer (if only one webcam is connected choose 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def jitter_block(input_image, block_size, randomness):\n",
    "    \"\"\"\n",
    "    Applies block-based shuffling to an image.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (ndarray): The input image represented as a NumPy array.\n",
    "        block_size (int): The size of the square block in pixels.\n",
    "        randomness (int): The randomness value controlling the intensity of jittering.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: The shuffled image as a NumPy array.\n",
    "    \"\"\"\n",
    "    height, width, _ = input_image.shape\n",
    "\n",
    "    # Calculate the number of blocks in each dimension\n",
    "    num_blocks_y = height // block_size\n",
    "    num_blocks_x = width // block_size\n",
    "\n",
    "    # Create a copy of the image to avoid modifying the original\n",
    "    jittered_image = np.copy(input_image)\n",
    "\n",
    "    for block_y in range(num_blocks_y):\n",
    "        for block_x in range(num_blocks_x):\n",
    "            # Calculate the coordinates of the block's top-left corner\n",
    "            start_x = block_x * block_size\n",
    "            start_y = block_y * block_size\n",
    "\n",
    "            # Calculate random offsets for the block's position\n",
    "            offset_x = np.random.randint(-randomness, randomness + 1)\n",
    "            offset_y = np.random.randint(-randomness, randomness + 1)\n",
    "\n",
    "            # Calculate the new position of the block\n",
    "            new_x = max(0, min(width - block_size, start_x + offset_x))\n",
    "            new_y = max(0, min(height - block_size, start_y + offset_y))\n",
    "\n",
    "            # Extract the block from the original image\n",
    "            block = input_image[start_y:start_y + block_size, start_x:start_x + block_size, :]\n",
    "\n",
    "            # Place the block at the new position in the jittered image\n",
    "            jittered_image[new_y:new_y + block_size, new_x:new_x + block_size, :] = block\n",
    "\n",
    "    return jittered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pixelate_image(input_image, division_block_size=2, dark_stretch_h=0, dark_stretch_v=0):\n",
    "    \"\"\"\n",
    "    Applies Pixelation on input image.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (ndarray): The input image represented as a NumPy array.\n",
    "        division_block_size (int): The size of the square block in pixels.\n",
    "        dark_stretch_h (int): The size of dark line in dimension 0 (horizontal).\n",
    "        dark_stretch_v (int): The size of dark line in dimension 1 (vertical).\n",
    "\n",
    "    Returns:\n",
    "        ndarray: The Pixelated image as a NumPy array.\n",
    "    \"\"\"\n",
    "    input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "    input_image = np.stack([np.zeros_like(input_image), input_image, np.zeros_like(input_image)], axis=-1)\n",
    "\n",
    "    height, width, _ = input_image.shape\n",
    "\n",
    "    input_image[[i + j for i in range(0, height, division_block_size) for j in range(dark_stretch_h)], :, :] *= 0\n",
    "    input_image[:, [i + j for i in range(0, width, division_block_size) for j in range(dark_stretch_v)], :] *= 0\n",
    "    input_image = cv2.GaussianBlur(input_image, (5, 5), 0)\n",
    "\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load YOLOv8 model for segmentation and background removal\n",
    "bg_model = YOLO(f\"bg_models/yolov8{yolov8_model_type}-seg.pt\")\n",
    "\n",
    "\n",
    "def bg_removal(input_image):\n",
    "    \"\"\"\n",
    "    Performs background removal on the input image.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (ndarray): The input image represented as a NumPy array.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the modified input image with background removed and the output mask.\n",
    "    \"\"\"\n",
    "    results = bg_model.predict(input_image.copy())[0]\n",
    "    output_mask = np.zeros_like(input_image, dtype='float32')\n",
    "    if results.masks:\n",
    "        for i in range(len(results.boxes.boxes)):\n",
    "            if int(results.boxes.boxes[i, -1].item()) == 0:\n",
    "                output_mask = results.masks.masks.detach().cpu()[i][..., None]\n",
    "                input_image = np.where(output_mask, input_image, 0)\n",
    "    return input_image, output_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load the MediaPipe Hands model\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "def hand_tracking(input_image):\n",
    "    \"\"\"\n",
    "    Performs hand tracking on the input image.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (ndarray): The input image represented as a NumPy array.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the modified input image with landmarks drawn and the calculated distance.\n",
    "    \"\"\"\n",
    "    # Detect hands in the image\n",
    "    results = hands.process(input_image[:, :, ::-1])\n",
    "\n",
    "    # Check if hands were detected\n",
    "    distance = None\n",
    "    if results.multi_hand_landmarks:\n",
    "        # Loop through each detected hand\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Draw landmarks on the image\n",
    "            mp_drawing.draw_landmarks(\n",
    "                input_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Get the landmarks of the thumb tip and index fingertip\n",
    "            thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "            index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "\n",
    "            # Calculate the distance between the thumb tip and index fingertip\n",
    "            distance = np.sqrt((thumb_tip.x - index_finger_tip.x) ** 2 + (thumb_tip.y - index_finger_tip.y) ** 2)\n",
    "\n",
    "            # Convert the coordinates to image pixel values\n",
    "            height, width, _ = input_image.shape\n",
    "            thumb_x, thumb_y = int(thumb_tip.x * width), int(thumb_tip.y * height)\n",
    "            index_x, index_y = int(index_finger_tip.x * width), int(index_finger_tip.y * height)\n",
    "\n",
    "            # Draw a line from thumb_tip to index_finger_tip\n",
    "            cv2.line(input_image, (thumb_x, thumb_y), (index_x, index_y), (0, 255, 0), 3)\n",
    "\n",
    "    # Return the modified image and distance\n",
    "    return input_image, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_webcam() -> None:\n",
    "    \"\"\"\n",
    "    Runs the webcam application for image processing and visualization.\n",
    "    Press 'q' to quit\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(webcam_number)\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "    dis = 0\n",
    "    while True:\n",
    "        ret, raw_frame = cap.read()\n",
    "        assert ret, 'webcam does not return image!!!'\n",
    "\n",
    "        frame, _ = bg_removal(raw_frame)\n",
    "        _, raw_dis = hand_tracking(raw_frame)\n",
    "        dis = int(raw_dis * 20) if raw_dis is not None else dis\n",
    "        dis = min(dis, 5)\n",
    "\n",
    "        frame = pixelate_image(frame, division_block_size=8, dark_stretch_h=2, dark_stretch_v=4)\n",
    "        frame = jitter_block(frame, 4, [0, 1, 2, 6, 12, 28][dis])\n",
    "\n",
    "        cv2.putText(frame, f\"Entropy: {'|' * (dis + 1)}\", (10, 30), font, 0.7, (255, 255, 255), 2)\n",
    "        cv2.imshow('WebCam', frame)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.36  Python-3.9.6 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 2060 SUPER, 8192MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27268704 parameters, 0 gradients, 110.2 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "run_webcam() # press q to quit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}